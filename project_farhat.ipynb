{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artilluminati/tgmanager/blob/main/project_farhat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP7f1-OzpRkK",
        "outputId": "303c5938-6601-4369-de9e-6b56e6cb317c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyTelegramBotApi\n",
            "  Downloading pyTelegramBotAPI-4.12.0.tar.gz (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotApi) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotApi) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotApi) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotApi) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotApi) (2023.7.22)\n",
            "Building wheels for collected packages: pyTelegramBotApi\n",
            "  Building wheel for pyTelegramBotApi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotApi: filename=pyTelegramBotAPI-4.12.0-py3-none-any.whl size=213952 sha256=6482dfa36fe4ebaaf6aef1bfb09615390a060e3b584e3adf4c8e59358e069491\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/ba/82/f3ab5bc48525778633bccc741c0424677ed3435736221819f4\n",
            "Successfully built pyTelegramBotApi\n",
            "Installing collected packages: pyTelegramBotApi\n",
            "Successfully installed pyTelegramBotApi-4.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyTelegramBotApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW7XHAVncDKB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import io\n",
        "from six.moves.urllib.request import urlopen\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "# import speech_recognition as speech_r\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "\n",
        "import telebot\n",
        "from telebot import types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PriteMdMcL7P"
      },
      "outputs": [],
      "source": [
        "# количество эпох обучения нейронки по генерации текста\n",
        "GENTEXT_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiI_YH7OhDGO"
      },
      "source": [
        "# 3. Генерация текста (Фархат)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUQPeQeyO6Ns"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iDfdCG5jot2",
        "outputId": "4e453e92-7758-4b1f-bc3e-7e6723b9b25f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-08-13 18:51:30--  https://raw.githubusercontent.com/artilluminati/utoolproject/main/describtion%20of%201000%20film.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1265755 (1.2M) [text/plain]\n",
            "Saving to: ‘describtion of 1000 film.txt’\n",
            "\n",
            "\r          describti   0%[                    ]       0  --.-KB/s               \rdescribtion of 1000 100%[===================>]   1.21M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-08-13 18:51:31 (21.8 MB/s) - ‘describtion of 1000 film.txt’ saved [1265755/1265755]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget 'https://github.com/artilluminati/utoolproject/blob/main/%D0%9C%D0%B0%D1%80%D0%B2%D0%B5%D0%BB.txt'\n",
        "\n",
        "!wget 'https://raw.githubusercontent.com/artilluminati/utoolproject/main/describtion%20of%201000%20film.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rMtMsxihG6O",
        "outputId": "6585134a-b2d4-4af3-8951-be7956e12fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1264978\n",
            "Epoch 1/10\n",
            "195/195 [==============================] - 22s 61ms/step - loss: 2.6283 - accuracy: 0.2894\n",
            "Epoch 2/10\n",
            "195/195 [==============================] - 12s 53ms/step - loss: 1.9850 - accuracy: 0.4132\n",
            "Epoch 3/10\n",
            "195/195 [==============================] - 12s 52ms/step - loss: 1.6919 - accuracy: 0.5007\n",
            "Epoch 4/10\n",
            "195/195 [==============================] - 12s 53ms/step - loss: 1.5064 - accuracy: 0.5529\n",
            "Epoch 5/10\n",
            "195/195 [==============================] - 12s 54ms/step - loss: 1.3912 - accuracy: 0.5831\n",
            "Epoch 6/10\n",
            "195/195 [==============================] - 13s 56ms/step - loss: 1.3109 - accuracy: 0.6040\n",
            "Epoch 7/10\n",
            "195/195 [==============================] - 14s 58ms/step - loss: 1.2486 - accuracy: 0.6209\n",
            "Epoch 8/10\n",
            "195/195 [==============================] - 15s 58ms/step - loss: 1.1953 - accuracy: 0.6345\n",
            "Epoch 9/10\n",
            "195/195 [==============================] - 13s 56ms/step - loss: 1.1475 - accuracy: 0.6475\n",
            "Epoch 10/10\n",
            "195/195 [==============================] - 13s 57ms/step - loss: 1.1018 - accuracy: 0.6595\n"
          ]
        }
      ],
      "source": [
        "path_to_file = 'describtion of 1000 film.txt'\n",
        "\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "print(len(text))\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab))\n",
        "tf.strings.unicode_split(text,\"UTF-8\")\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text,\"UTF-8\"))\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert = True)\n",
        "\n",
        "seq_length = 100\n",
        "sequences = ids_dataset.batch(seq_length+1,drop_remainder=True)\n",
        "\n",
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "  def call(self, x, states = None, training = False, return_state = False):\n",
        "    x = self.embedding(x, training = training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "model = MyModel(vocab_size = vocab_size, embedding_dim = embedding_dim, rnn_units=rnn_units)\n",
        "\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer='adam',loss=loss, metrics=(['accuracy']))\n",
        "history = model.fit(dataset, epochs=GENTEXT_EPOCHS)\n",
        "\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    #\n",
        "    skip_ids = self.ids_from_chars(['UNK'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        values = [-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())]\n",
        "    )\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self,inputs,states=None):\n",
        "    # превращаем строки в айдишники\n",
        "    input_chars = tf.strings.unicode_split(inputs,\"UTF-8\")\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # запускаем модель, которую обучали выше\n",
        "    predicted_logits, states = self.model(x=input_ids, states=states, return_state=True)\n",
        "\n",
        "    predicted_logits = predicted_logits[:,-1,:]\n",
        "    predicted_logits = predicted_logits / self.temperature\n",
        "\n",
        "    # применяем UNK вместо неизвестных символов если они есть\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # генерируем символ\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    return predicted_chars, states\n",
        "\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars,temperature=0.5)\n",
        "\n",
        "# states = None\n",
        "# next_char = tf.constant(['hello'])\n",
        "# result = [next_char]\n",
        "# for n in range(1000):\n",
        "#   next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "#   result.append(next_char)\n",
        "\n",
        "# result = tf.strings.join(result)\n",
        "# print(result[0].numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d_JqAswNdbYI"
      },
      "outputs": [],
      "source": [
        "token = '6462253731:AAE7YJlLzeT9uK3WKuqO5Kv_yvIABGxAeec'\n",
        "\n",
        "bot = telebot.TeleBot(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0dG2hnHLdQ1o"
      },
      "outputs": [],
      "source": [
        "@bot.message_handler(commands=(['start', 'generate']))\n",
        "def generate_text(message):\n",
        "  mesg = bot.send_message(message.chat.id, 'Напиши какой-нибудь текст, а нейросеть продолжит его за тебя.\\nНо пиши его на английском языке!')\n",
        "  bot.register_next_step_handler(mesg, generate)\n",
        "\n",
        "def generate(message):\n",
        "  try:\n",
        "    bot.send_message(message.chat.id, 'Генерация текста...')\n",
        "    states = None\n",
        "    next_char = tf.constant([message.text])\n",
        "    result = [next_char]\n",
        "    for n in range(1000):\n",
        "      next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "      result.append(next_char)\n",
        "\n",
        "    result = tf.strings.join(result)\n",
        "    bot.send_message(message.chat.id, result[0].numpy().decode('utf-8'))\n",
        "  except Exception as err:\n",
        "    bot.send_message(message.chat.id, 'Произошла ошибка:', err)\n",
        "\n",
        "@bot.message_handler(commands=(['return', 'movie', 'movielegacy']))\n",
        "def generate_text(message):\n",
        "  try:\n",
        "    keyboardUrl2 = types.InlineKeyboardMarkup()\n",
        "    url_button = types.InlineKeyboardButton(text=\"Вернуться\", url=\"http://t.me/utoolproject_bot\")\n",
        "    keyboardUrl2.add(url_button)\n",
        "    bot.send_message(message.chat.id, 'Вернуться к основному боту', reply_markup = keyboardUrl2)\n",
        "  except:\n",
        "    bot.send_message(message.chat.id, 'Вернуться к основному боту @utoolproject_bot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23jSl_Zdpd7h"
      },
      "outputs": [],
      "source": [
        "bot.polling()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}